{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNi0QMOFFcC7IhrI1CqKCs4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "7Q5OCNRHBJLq"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "from numpy import asarray"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "custom_vision_imgurl = 'https://<resource_name>.cognitiveservices.azure.com/customvision/v3.0/Prediction/<project_id>/detect/iterations/<published_name>/image'\n",
        "api_key = '<YOUR_PREDICTION_KEY>'"
      ],
      "metadata": {
        "id": "3OrHX9ODBP5x"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = open('1.jpg', 'rb').read()\n",
        "img = cv2.imdecode(np.array(bytearray(data), dtype='uint8'), cv2.IMREAD_COLOR)\n",
        "\n",
        "# it's for one picture"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "n9AtulEOBdox",
        "outputId": "142fede5-4380-4840-a57f-d9b33155040e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '1.jpg'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-5545b88b6495>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'1.jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'uint8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_COLOR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# it's for one picture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '1.jpg'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### tag-id、boundingbox"
      ],
      "metadata": {
        "id": "WRxT9HAECQEF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "custom_vision_headers = {\n",
        "    'Content-Type': 'application/octet-stream',\n",
        "    'Prediction-Key': api_key\n",
        "    }\n",
        "\n",
        "custom_vision_resp = requests.post(url = custom_vision_imgurl,\n",
        "    data = data,\n",
        "    headers = custom_vision_headers).json()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "7wbv-2qBB61G",
        "outputId": "77f815cc-75a0-4169-f8cd-6bdb38c346fd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'data' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-c43b279fc56c>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m custom_vision_resp = requests.post(url = custom_vision_imgurl,\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     headers = custom_vision_headers).json()\n",
            "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hit = pd.DataFrame(custom_vision_resp['predictions']).sort_values(by='probability',ascending=False).head(1).to_dict()\n",
        "\n",
        "print(hit)"
      ],
      "metadata": {
        "id": "yd2q6Ue3CBk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extract the bounding box for the detected number plate\n",
        "boundingbox = list(hit['boundingBox'].values())[0]\n",
        "l, t, w, h = (boundingbox['left'],\n",
        "    boundingbox['top'],\n",
        "    boundingbox['width'],\n",
        "    boundingbox['height'])\n",
        "\n",
        "# extract bounding box coordinates and dimensions are scaled using image dimensions\n",
        "polylines1 = np.multiply([[l,t],[l+w,t],[l+w,t+h],[l,t+h]],\n",
        "    [img.shape[1],img.shape[0]])\n",
        "\n",
        "# draw polylines based on bounding box results\n",
        "temp_img = cv2.polylines(img, np.int32([polylines1]),\n",
        "    isClosed = True, color = (255, 255, 0), thickness = 2)\n",
        "\n",
        "# display the original image with the plate region\n",
        "plt.imshow(cv2.cvtColor(temp_img, cv2.COLOR_BGR2RGB))"
      ],
      "metadata": {
        "id": "hHshfui_Ca3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### choose the license place"
      ],
      "metadata": {
        "id": "5XwXrLFLCjaM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# crop the image to the bounding box of the plate region\n",
        "crop_x = polylines1[:,0].astype('uint16')\n",
        "crop_y = polylines1[:,1].astype('uint16')\n",
        "\n",
        "img_crop = img[np.min(crop_y):np.max(crop_y),\n",
        "    np.min(crop_x):np.max(crop_x)]\n",
        "\n",
        "# display the detected plate region\n",
        "plt.imshow(cv2.cvtColor(img_crop, cv2.COLOR_BGR2RGB))"
      ],
      "metadata": {
        "id": "kq9H8-_DCiv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OCR take the text\n",
        "### 在調用Azure Computer Vision API之前,我們必須確保發送的圖像具有至少50像素的高度"
      ],
      "metadata": {
        "id": "azGxoRt9F7mz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_crop_height = img_crop.shape[0]\n",
        "if img_crop_height < 50:\n",
        "      pil_image = Image.fromarray(img_crop)\n",
        "      img_crop_width = img_crop.shape[1]\n",
        "      difference = 50 / img_crop_height\n",
        "      resized_dimensions = (int(img_crop_width * difference), int(img_crop_height * difference))\n",
        "      pil_image_resized = pil_image.resize(resized_dimensions)\n",
        "      img_crop_resized = asarray(pil_image_resized)\n",
        "\n",
        "      plt.imshow(cv2.cvtColor(img_crop_resized, cv2.COLOR_BGR2RGB))"
      ],
      "metadata": {
        "id": "FHSag4z9F68-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### OCR tag-id、boundingbox"
      ],
      "metadata": {
        "id": "OnuspE3-H0ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "computer_vision_imgurl ="
      ],
      "metadata": {
        "id": "_SocGg9kJrNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "建立這個：https://portal.azure.com/#create/Microsoft.CognitiveServicesComputerVision\n",
        "\n",
        "建好之後用圖片轉文字，將訓練好的網址貼到上面"
      ],
      "metadata": {
        "id": "PCnM5aZ1OA1N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "crop_bytes = bytes(cv2.imencode('.png', img_crop_resized)[1])\n",
        "\n",
        "# make a call to the computer_vision_imgurl\n",
        "computer_vision_resp = requests.post(\n",
        "    url=computer_vision_imgurl,\n",
        "    data=crop_bytes,\n",
        "    headers={\n",
        "        'Ocp-Apim-Subscription-Key': api_key,\n",
        "        'Content-Type': 'application/octet-stream'}).json()"
      ],
      "metadata": {
        "id": "bIaI8811Hyer"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "computer_vision_resp"
      ],
      "metadata": {
        "id": "Pmq_XmfpHz8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('The plate number is {}'.format(computer_vision_resp['readResult']['content']))"
      ],
      "metadata": {
        "id": "ncYcO7R4H8UX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}